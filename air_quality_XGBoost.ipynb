 {
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**[Predict Air Quality with Machine Learning](https://www.sciencebuddies.org/science-fair-projects/project-ideas/)**\n",
        "\n",
        "This notebook was developed by Science Buddies [www.sciencebuddies.org](https://www.sciencebuddies.org/) as part of a science project to allow students to explore and learn about artificial intelligence. For personal use, this notebook can be downloaded and modified with attribution. For all other uses, please see our [Terms and Conditions of Fair Use](https://www.sciencebuddies.org/about/terms-and-conditions-of-fair-use).  \n",
        "\n",
        "**Troubleshooting tips**\n",
        "*   Read the written instructions at Science Buddies and the text and comments on this page carefully.\n",
        "*   If you make changes that break the code, you can download a fresh copy of this notebook and start over.\n",
        "\n",
        "*   If you are using this notebook for a science project and need help, visit our [Ask an Expert](https://www.sciencebuddies.org/science-fair-projects/ask-an-expert-intro) forum for assistance."
      ],
      "metadata": {
        "id": "BcuCkOZ6kpuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How To Use This Notebook**\n",
        "\n",
        "This notebook contains text fields, like this one, that give you information about the project and instructions."
      ],
      "metadata": {
        "id": "QX_j2WczkzTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are also code blocks, like this one.\n",
        "\n",
        "# The green text in a code block are comments. Comments are descriptions of what the code does.\n",
        "\n",
        "# The non-green text in a code block is the Python code. Click on the triangle in the top left corner to run this code block.\n",
        "\n",
        "print(\"Congratulations, you ran a code block! Try changing the text in the code and running it again.\")"
      ],
      "metadata": {
        "id": "tWitXiz8kzq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9K5kG_8kiC0"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icfhtbxlkXrk"
      },
      "outputs": [],
      "source": [
        "# Standard Library\n",
        "import os\n",
        "\n",
        "# Data Science Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Plotting Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learning Libraries (Scikit-learn)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Deep Learning Libraries (TensorFlow/Keras)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import InputLayer, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n1nRdK8kojC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzH4MHZPkte9"
      },
      "source": [
        "# 3. Loading the Data into a Pandas DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 3A"
      ],
      "metadata": {
        "id": "2-4w_nn-zzXP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyz2fTrbkv9W"
      },
      "outputs": [],
      "source": [
        "# Define the path to the CSV file containing air quality data\n",
        "csv_path = '/content/drive/MyDrive/Air Quality Prediction/aqidaily_fiveyears.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame using pandas\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Display the first 5 rows of the DataFrame to check the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rznEm9BQQutp"
      },
      "source": [
        "# 4. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 4A"
      ],
      "metadata": {
        "id": "0CmNA8cfAKWd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aYj3dRFdIHk"
      },
      "outputs": [],
      "source": [
        "# Convert the 'Date' column to datetime format and set it as the DataFrame index\n",
        "df.index = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Display the first 5 rows of the updated DataFrame to verify the changes\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 4B"
      ],
      "metadata": {
        "id": "fL5oW5ulBNl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm8ON2obdnNf"
      },
      "outputs": [],
      "source": [
        "# Extract the 'Overall AQI Value' column from the DataFrame and store it in a variable 'temp'\n",
        "temp = df['Overall AQI Value']\n",
        "\n",
        "# Plot the values in the 'temp' series to visualize the trend of the AQI over time\n",
        "temp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 4C"
      ],
      "metadata": {
        "id": "CqELIeBLCThU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzVNsDuJR4Ls"
      },
      "outputs": [],
      "source": [
        "# Drop the unnecessary columns\n",
        "df.drop(columns=['Site Name (of Overall AQI)'], inplace=True)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 4D"
      ],
      "metadata": {
        "id": "G7yDBJCOik_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert columns to numeric, coercing errors to NaN\n",
        "df['CO'] = pd.to_numeric(df['CO'], errors='coerce')\n",
        "df['Ozone'] = pd.to_numeric(df['Ozone'], errors='coerce')\n",
        "df['PM10'] = pd.to_numeric(df['PM10'], errors='coerce')\n",
        "df['PM25'] = pd.to_numeric(df['PM25'], errors='coerce')\n",
        "df['NO2'] = pd.to_numeric(df['NO2'], errors='coerce')\n",
        "\n",
        "# Replace '-' with NaN\n",
        "df.replace('-', np.nan, inplace=True)\n",
        "\n",
        "# Fill Null values (if any) with last known number\n",
        "df.ffill(inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "owJl8Ez5h5wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 4E"
      ],
      "metadata": {
        "id": "mShOxDiuD9tK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf792HYuTbrp"
      },
      "outputs": [],
      "source": [
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# TODO: Select the columns to normalize\n",
        "columns_to_normalize = ['CO', 'Ozone', 'PM10', 'PM25', 'NO2']\n",
        "\n",
        "# Fit and transform the data\n",
        "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 4F"
      ],
      "metadata": {
        "id": "HHGKLet1R64w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0BDn3_RmfO9"
      },
      "outputs": [],
      "source": [
        "def df_to_X_y(df, window_size=5):\n",
        "    # Convert the input dataframe to a NumPy array for easier manipulation\n",
        "    df_as_np = df.to_numpy()\n",
        "\n",
        "    # Initialize empty lists to hold the features (X), labels (y), and indices\n",
        "    X = []\n",
        "    y = []\n",
        "    indices = []\n",
        "\n",
        "    # Iterate over the length of the dataframe minus the window size\n",
        "    for i in range(len(df_as_np) - window_size):\n",
        "        # Extract a 'window' of values from the dataframe (a slice of rows)\n",
        "        # and format each value as a list (to keep consistent dimensionality)\n",
        "        row = [[a] for a in df_as_np[i:i + window_size]]\n",
        "\n",
        "        # Append the windowed rows to the feature list X\n",
        "        X.append(row)\n",
        "\n",
        "        # The label (y) is the value that follows the current window\n",
        "        label = df_as_np[i + window_size]\n",
        "\n",
        "        # Append the label to the label list y\n",
        "        y.append(label)\n",
        "\n",
        "        # Append the starting index of the window to the indices list\n",
        "        indices.append(df.index[i])\n",
        "\n",
        "    # Convert the feature (X) and label (y) lists into NumPy arrays and return them along with the indices\n",
        "    return np.array(X), np.array(y), np.array(indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 4G"
      ],
      "metadata": {
        "id": "aKHuL2x9S_UY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixn36n8A1Vw5"
      },
      "outputs": [],
      "source": [
        "# TODO: Change the window size to reflect how many days in advance we want to predict AQI\n",
        "WINDOW_SIZE = 365  # Define the size of the sliding window (number of time steps to consider for each sequence)\n",
        "\n",
        "# X will contain sequences of length 'WINDOW_SIZE', and y will contain the corresponding labels (next values)\n",
        "X, y, indices = df_to_X_y(temp, WINDOW_SIZE)\n",
        "\n",
        "# Output the shapes of X and y to check the dimensions\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilKPeR_RUEXx"
      },
      "source": [
        "## 5. Split to Train, Validation, and Test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 5A"
      ],
      "metadata": {
        "id": "3H7T3UlBVvTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLwbt4xR2HrM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X, y, and indices are already defined\n",
        "indices = np.arange(len(X))  # Create an array of indices (or use the actual indices if available)\n",
        "\n",
        "# Step 1: Split the dataset into training+validation and test sets, preserving indices\n",
        "X_train_val, X_test, y_train_val, y_test, indices_train_val, indices_test = train_test_split(\n",
        "    X, y, indices, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Split the training+validation set into training and validation sets, preserving indices\n",
        "X_train, X_val, y_train, y_val, indices_train, indices_val = train_test_split(\n",
        "    X_train_val, y_train_val, indices_train_val, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# Now you have the features (X), labels (y), and corresponding indices for each split."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 5B"
      ],
      "metadata": {
        "id": "s70eNcVmhutP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, you have:\n",
        "# X_train, y_train: Training set (60%)\n",
        "# X_val, y_val: Validation set (20%)\n",
        "# X_test, y_test: Test set (20%)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "Qyh1kRaihwER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAqS69aQUMzd"
      },
      "source": [
        "# 6. Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 6A"
      ],
      "metadata": {
        "id": "9mGkPUqHi1P0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C1d2edX3aon"
      },
      "outputs": [],
      "source": [
        "# Create a Sequential model (builds the model layer by layer)\n",
        "model = Sequential()\n",
        "\n",
        "# Add an input layer that expects sequences of length WINDOW_SIZE with 1 feature per time step\n",
        "model.add(InputLayer(input_shape=(WINDOW_SIZE, 1)))\n",
        "\n",
        "# Add an LSTM layer with 64 units (neurons) to learn patterns from the sequential data\n",
        "model.add(LSTM(64))\n",
        "\n",
        "# Add a Dense (fully connected) layer with 8 neurons and ReLU activation to introduce non-linearity\n",
        "model.add(Dense(8, activation='relu'))\n",
        "\n",
        "# Add a final Dense layer with 1 neuron and linear activation to produce the predicted output (one value)\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Print a summary of the model's layers and the number of parameters in each layer\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 6B"
      ],
      "metadata": {
        "id": "MNEdBw85j9Wq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKF89iFG33Tb"
      },
      "outputs": [],
      "source": [
        "# Create a ModelCheckpoint callback to save the model to 'model.keras' only when its performance improves\n",
        "cp = ModelCheckpoint('/content/drive/MyDrive/Air Quality Prediction/model.keras', save_best_only=True)\n",
        "\n",
        "# Compile the model, specifying the loss function, optimizer, and evaluation metric\n",
        "# - loss=MeanSquaredError(): Measures how well the model is performing by calculating the average squared difference between predictions and actual values\n",
        "# - optimizer=Adam(learning_rate=0.001): Adam optimizer adjusts the learning rate during training; here we set the initial learning rate to 0.001\n",
        "# - metrics=[RootMeanSquaredError()]: The model will evaluate its performance using RMSE, which is a common metric in regression tasks\n",
        "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 6C"
      ],
      "metadata": {
        "id": "FKjmrm4Xkxsg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kQR_JP84V9J",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Train the model using the training data (X_train, y_train)\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=[cp])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-YBdTLfUTag"
      },
      "source": [
        "# 7. Evaluating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 7A"
      ],
      "metadata": {
        "id": "Bud55bnRljsW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkYkTqe74we_"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model from the specified file path\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Air Quality Prediction/model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 7B"
      ],
      "metadata": {
        "id": "qajQafHgmCQK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpYdrJVz590F"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "# Set the starting date\n",
        "# start_date = pd.to_datetime('2019-01-01')\n",
        "start_date = pd.to_datetime(df.index.min())\n",
        "\n",
        "# Create a date range that covers the maximum index\n",
        "max_index = indices_test.max()\n",
        "date_range = pd.date_range(start=start_date, periods=max_index + 1)\n",
        "\n",
        "# Use the indices to select corresponding dates from the date range\n",
        "date_index = date_range[indices_test]\n",
        "\n",
        "# Example data\n",
        "data = {'Date': date_index, 'y_test': y_test, 'y_pred': y_pred}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set 'Date' as the index\n",
        "df.set_index('Date', inplace=True)\n",
        "\n",
        "# Sort the DataFrame by the index (Date) in ascending order\n",
        "df.sort_index(ascending=True, inplace=True)\n",
        "\n",
        "# View the sorted DataFrame\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 7C"
      ],
      "metadata": {
        "id": "hcVKuV9oNVYO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbTUq0-Y6Ccd"
      },
      "outputs": [],
      "source": [
        "# Plot the values against the date index\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot y_test\n",
        "plt.plot(df.index, df['y_test'], label='Actual Values (y_test)', color='blue', marker='o')\n",
        "\n",
        "# Plot y_pred\n",
        "plt.plot(df.index, df['y_pred'], label='Predicted Values (y_pred)', color='red', linestyle='--', marker='x')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('y_test vs. y_pred over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Values')\n",
        "plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 7D"
      ],
      "metadata": {
        "id": "jqFJOuKEN-v4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeZ0i2e6NqQT"
      },
      "outputs": [],
      "source": [
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 7E"
      ],
      "metadata": {
        "id": "K42EZ4v_OhC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")"
      ],
      "metadata": {
        "id": "mVObW-g3oov2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Block 7F"
      ],
      "metadata": {
        "id": "0ebGkrFIPjCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Fit a best-fit line\n",
        "model = LinearRegression()\n",
        "y_test_reshaped = np.array(y_test).reshape(-1, 1)  # Reshape for fitting\n",
        "model.fit(y_test_reshaped, y_pred)\n",
        "y_best_fit = model.predict(y_test_reshaped)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.5, label=\"Predicted vs. Actual\")\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label=\"Perfect Prediction\")\n",
        "plt.plot(y_test, y_best_fit, color='green', linestyle='-', label=\"Best Fit Line\")\n",
        "plt.xlabel(\"True Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(f\"True vs Predicted Values (R² = {r2:.2f})\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I3bxDk1e75e9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
